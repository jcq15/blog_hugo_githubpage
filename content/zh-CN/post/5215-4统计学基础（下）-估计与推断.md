---
title: "统计学基础（下）-点估计"
date: 2021-12-28T14:13:04+08:00
draft: false
tags: [
"学习",
]
categories: ["课程笔记"]
series: ["课程笔记"]
math: true
---

妙啊。

<!--more-->

## 点估计

设 $X_1,\cdots,X_n\sim P_\theta\in\mathcal{P}$，其中 $\theta=(\theta_1,\cdots,\theta_k)\in\Theta$. 这是经典的参数模型。如前所述，**估计量（estimator）**是统计量 $\hat\theta=w(X_1,\cdots,X_n)$. 我们下面来介绍得到 $\hat\theta$ 的方法。

### 矩估计

通常来说 $j$ 阶矩都和参数有关，即 $E_\theta X_1^j=h_j(\theta)$. 假设 $\theta$ 是 $k$ 维的，令 $h(\theta)=(h_1(\theta),\cdots,h_k(\theta))$. 若该存在的都存在，就可以淦了：
$$
\hat\theta_j=h_j^{-1}\left(\frac{1}{n}\sum_{i=1}^nX_i^j\right).
$$
### 极大似然估计

似然函数定义为
$$
l(\theta;X)=f_\theta(X).
$$
就是密度函数，不过变量变成了 $\theta$。极大似然估计为
$$
\hat\theta=\mathop{\arg\max}_{\theta\in\Theta}\ l(\theta;X).
$$
对于指数族
$$
l(\eta;x)=\exp\left(\eta^T(\theta)T(x)-\xi(\theta)\right)h(x),
$$
如果各种反函数存在，可以证明 MLE 是
$$
\hat\theta=\eta^{-1}\left(\mu^{-1}(T(x))\right).
$$

### M-估计

是 MLE 的推广，似然函数被换成一般函数 $s_\theta:\mathcal{X}\to\bar{\mathbb{R}}$，估计值是使得 $S_n(\theta)=\dfrac{1}{n}\sum_{i=1}^n s_\theta(X_i)$ 最大的 $\theta$.

## 估计的评价

### 一般理论

**决策规则（decision rule）**是将观察结果转换为适当动作的函数。对于一般的统计问题，我们首先获取样本 $X$，记 allowable actions（不知道咋翻译最恰当）为集合 $\mathbb{A}$. 一个决策规则 $T$ 便是把 $X$ 映射为 $\mathbb{A}$ 中 $T(X)$ 的过程。

**损失函数（loss function）** $L(P,T(x))$ 表示当真实分布为 $P$ 时，观察到 $X=x$ 时执行决策 $T(X)$ 的损失。

**风险（risk）**表示平均损失，即
$$
R_T(P)=\mathrm E_P\left(L(P,T(X))\right)=\int L(P,T(X))dP.
$$
我们自然希望风险越小越好。对于两个决策规则 $T_1,T_2$，我们称：

- $T_1$ **as good as** $T_2$，如果 $R_{T_1}(P)\le R_{T_2}(P),\forall P\in\mathcal{P}$,
- $T_1$ **better than** $T_2$，如果 $T_1$ **as good as** $T_2$ 且对某个 $P$，$R_{T_1}(P)<R_{T_2}(P)$,
- $T_1$ 和 $T_2$ **equivalent**，如果 $R_{T_1}(P)=R_{T_2}(P),\forall P\in\mathcal{P}$.

> 这个 as good as 应该理解为“不差于”。

接下来我们有两个问题：

- 如何确定风险函数 $R$
- 确定了 $R$ 之后，如何根据 $R$ 来选择最优的决策

### 几种“最优”

假设我们有一堆可选的决策规则，记作集合 $\mathfrak{J}$. 给定 $R$ 之后，如何选择“最优”呢？

**Optimal**：如果 $T_*$ as good as $\mathfrak{J}$ 中其他规则，则称它 **$\mathfrak{J}$-optimal**. 在“所有可能的决策规则”可以构成集合时，若 $T_*$ as good as 所有可能的决策规则，则称为 **optimal**。

> Optimal 就是所谓的“完爆”。

显然，optimal 不一定存在，我们需要新的定义。

> “炉石传说没有完爆！”——银背族长

**Admissible**：如果不存在比 $T_*$ better 的规则，则称它 **$\mathfrak{J}$-admissible**（或 admissible）。

**Minimax**：$\sup_P R_{T_*}(P)\le\sup_P{R_{T}}(P)$，则 $T_*$ 是 minimax。

**Bayes-rule**：考虑 Bayes risk
$$
r_T(\Pi)=\int_\mathcal{P}R_T(P)d\Pi(P).
$$
给定 $\Pi$，如果 $T_*$ 满足 $r_{T_*}\le r_T$，就叫 Bayes rule w.r.t. $\Pi$。要寻找 Bayes rule 下的最优决策，可以考虑 $\mathrm E\left(\mathrm E\left(L(\theta,T(X))|X\right)\right)$.

### 点估计的评价（点估计的风险函数）

#### MSE

我们把上面的理论套用起来。我们用 $\hat\theta$ 表示估计量，也就是上面的 $T(X)$. 常用的风险函数为**均方误差（mean squared error, MSE）**。MSE 对应的损失函数为 $L(P_\theta,\hat\theta)=(\theta-\hat\theta)^2$，对应的风险函数为
$$
MSE=\mathrm E_\theta\left((\theta-\hat\theta)^2\right).
$$
我们定义**偏差（bias）**：
$$
b_T(\theta)=\mathrm E_\theta(\hat\theta)-\theta,
$$
则有 $
\mathrm E_\theta\left((\theta-\hat\theta)^2\right)=\mathrm E_\theta\left((\theta-\mathrm E\hat\theta)^2\right)+\left(\mathrm E\hat\theta-\theta\right)^2$，即
$$
MSE(\theta)=b^2(\theta)+\mathrm{Var}(\theta).
$$

#### Rao-Blackwall 定理

如下定理表明，我们可以考虑充分统计量的条件期望来构造更好的估计。

**定理（Rao-Blackwall）** 设 $T$ 是充分统计量。若参数空间 $\Theta$ 是凸集，$S_0(X)$ 满足 $\mathrm E_P|S_0|<\infty,\forall P\in\mathcal{P}$. 令 $S_1=\mathrm E(S_0(X)|T)$，则

- 若损失函数 $L(P,a)$ 关于 $a$ 是凸函数，则 $R_{S_1}(P)\le R_{S_0}(P)$；
- 若 $L(P,a)$ 严格凸，且 $S_0$ 不是 $T$ 的函数，则 $S_1$ better than $S_0$.

读者自证不难。（为什么要求 $T$ 是充分统计量？）

#### UMVUE

uniformly minimum variance unbiased estimator. 即对所有 $P$ （一致），$\mathrm{Var}(T_*(X))\le\mathrm{Var}(T(X))$（最小），且无偏（相当于规定 $\mathfrak{J}$ 是无偏估计，然后寻找 MSE 下的最优估计）。我们下面介绍几种寻找 UMVUE 的方法。

**方法一：定理（Lehmann-Scheffe）** 设 $T(X)$ 充分且完备，若 $\theta$ 的无偏估计存在，则存在唯一的形如 $h(T)$ 的无偏估计，且 $h(T)$ 是唯一的 UMVUE。

这个定理告诉我们，想获得 UMVUE，可以先找充分且完备的统计量 $T(X)$，然后尝试 $h(T)$，使得 $\mathrm Eh(T)=\theta$. 那如果找不到呢？可以用下面的定理。

**方法二：定理** 设 $\mathcal{U}=\{T(X):\mathrm E(T)=0 \text{ and }\mathrm{Var}(T)<\infty\}$，设 $T$ 是参数的无偏估计且 $\mathrm E(T^2)<\infty$. 令内积为 $\langle X,Y\rangle=\mathrm E(XY)$. 则：

- $T$ 是 UMVUE 的充要条件是 $T\perp \mathcal{U}$（对任意 $P$）.
- 设 $S$ 是充分统计量，且 $T=h(S)$. 令 $\mathcal{U}_S=\{U\in\mathcal{U}:U=\varphi(S)\}$. $T$ 是 UMVUE 的充要条件是 $T\perp \mathcal{U}_S$ （对任意 $P$）.

**推论**

- （线性）设 $T_j$ 是 $\eta_j$ 的 UMVUE，方差有限，则 $T=\sum_{j=1}^k c_jT_j$ 是 $\eta=\sum_{j=1}^k c_j\eta_j$ 的 UMVUE.
- （唯一性）设 $T_1,T_2$ 是 $\eta$ 的 UMVUE，方差有限，则 $T_1=T_2$ a.s..

**方法三：C-R 下界**。寻找 UMVUE 的另一种思路是，找到方差的下界。这样只要我们得到一个无偏估计，其方差等于下界，就一定是 UMVUE 了。为此，我们需要一坨子新东西。

**定义（Fisher information）** 有一分布族 $\mathcal{P}=\{f_\theta\}$. $X$ 是服从 $f_\theta$ 的样本。如果该存在的都存在，则定义 Fisher information
$$
I(\theta)=\mathrm E\left(\frac{\partial}{\partial\theta}\log f_\theta (X)\right)^2.
$$
**性质1** （自行证明）若 $\dfrac{\partial^2}{\partial\theta^2}f_\theta$ 存在，且满足光滑性条件：
$$
\begin{gather}
\frac{\partial}{\partial\theta}\int f_\theta(x)dx=\int \frac{\partial f_\theta(x)}{\partial\theta}dx, \\
\frac{\partial}{\partial\theta}\int \frac{\partial f_\theta (x)}{\partial\theta}dx=\int \frac{\partial^2 f_\theta (x)}{\partial\theta^2}dx,\\

\end{gather}
$$
则有
$$
I(\theta)=-\mathrm E\left(\dfrac{\partial^2}{\partial\theta^2}\log f_\theta(X)\right).
$$
**性质2** 若 $X,Y$ 独立，则 $I_{X+Y}=I_X+I_Y$.

**定理（Cramer-Rao 下界）** 满足上述光滑性条件时，若 $T(X)$ 是 $g(\theta)$ 的无偏估计，且满足
$$
g'(\theta)=\frac{\partial}{\partial\theta}\int T(x)f_\theta(x)dx=\int T(x)\frac{\partial}{\partial\theta}f_\theta(x)dx,
$$
则 $\mathrm{Var}(T(X))\ge\dfrac{g'(\theta)^2}{I(\theta)}$.

我们可以将其推广到参数为多元的情况。若 $\theta$ 是向量，记 $\dfrac{\partial}{\partial\theta}$ 为梯度（列向量）。则信息矩阵
$$
I(\theta)=\mathrm E\left\{\frac{\partial\log f_\theta(x)}{\partial\theta}\left[\frac{\partial\log f_\theta(x)}{\partial\theta}\right]^T\right\}.
$$
相应的，光滑性条件也是矩阵（或向量）的每个位置都满足。此时 Cramer-Rao 下界为
$$
\mathrm{Var}(T(X))\ge\left(\frac{\partial g(\theta)}{\partial\theta}\right)^TI^{-1}(\theta)\frac{\partial g(\theta)}{\partial\theta}.
$$
**指数族** 对于指数族，我们又有福利了。若
$$
f_\theta(x)=\exp\left[\eta^T(\theta)T(x)-\xi(\theta)\right]h(x),
$$
则:

- 对满足 $E|S(X)|<\infty$ 的 $S$，上面乱七八糟的光滑性条件都成立，即
  - $
  \frac{\partial}{\partial\theta}\int S(x)f_\theta(x)dx=\int S(x)\frac{\partial}{\partial\theta}f_\theta(x)dx
  $,
  - $I(\theta)=-\mathrm E\left(\dfrac{\partial^2}{\partial\theta^2}\log f_\theta(X)\right)$. 
- 此外还有 $
\mathrm{Var}(T)=I(\eta)$,
- 令 $\psi=\mathrm E(T(X))$，则 $\mathrm{Var}(T)=I^{-1}(\psi)$.


## 假设检验

设 $\mathcal{P}$ 是分布族，$\mathcal{P}_0\in\mathcal{P},\mathcal{P}_1=\mathcal{P}\setminus\mathcal{P}_0$. 一般的假设检验问题需要决定以下两个假设哪个是对的：
$$
H_0:P\in\mathcal{P}_0,\\
H_1:P\in\mathcal{P}_1.
$$
动作空间 $\mathbb{A}=\{0,1\}$. 此时的决策规则 $T=I_C(X)$，即 $X\in C$ 时选择 $H_1$，否则选择 $H_0$. $C$ 被称为**拒绝域（rejection region）**（因为拒绝了 $H_0$）。

### 两类错误

**第一类错误（type I error）**指 $H_0$ 成立，但拒绝了 $H_0$.

**第二类错误（type II error）**指 $H_0$ 不成立，但接受了 $H_0$.

我们定义**功效函数（power function）**为第一类错误的概率，即
$$
\alpha_T(P)=P(X\in C).
$$
假设检验的 **size** 定义为功效的上确界，即
$$
\alpha'=\sup_{P\in\mathcal{P}_0} P(X\in C).
$$

## 渐近分析（slides 19）

许多时候我们无法得到 $T_n$ 的确切分布，这时候考虑 $T_n$ 的极限性质会大有帮助。

### 一致性

**定义** 

- $T_n(X)$ 是 $\theta$ 的**一致估计（consistent）**，当且仅当 $T_n(X)\overset{p}\to\theta$.
- $T_n(X)$ 是 $\theta$ 的**强一致估计（strongly consistent）**，当且仅当 $T_n(X)\overset{a.s.}\to\theta$.
- $\{a_n\}$ 是一个正数列，$a_n\to\infty$，称 $T_n(X)$ **$a_n$-consistent**，当且仅当 $a_n[T_n(X)-\theta]=O_P(1)$.
- $T_n(X)$ 称为 **$L_r$-consistent**，当且仅当 $T_n(X)\overset{L^r}\to\theta$.

显然其他几种一致性都能推出第一种 trivial consistent.

### 渐近偏差与渐近方差

**渐近无偏**：$b_n\to 0$.

**渐近期望**：数列 $a_n\to\infty$ 或 $a_n\to a>0$，若 $a_n\xi_n\overset{d}\to \xi$ 且 $\mathrm E|\xi|<\infty$，则 $\mathrm E\xi/a_n$ 称为渐近期望。

**渐近偏差**：$T_n-\theta$ 的渐近期望。

**渐近MSE**：$a_n(T_n-\theta)\overset{d}\to Y$，则 $\text{amse}=\mathrm E Y^2/a_n^2$.

**渐近方差**：$a_n(T_n-\theta)\overset{d}\to Y$，则渐近方差为 $\mathrm{Var}Y/a_n^2$.

高维的情况：设 $\hat\theta_n$ 是一列估计（$k$ 维向量），若存在正定矩阵 $V_n(\theta)$ 使得
$$
[V_n(\theta)]^{-1/2}(\hat\theta_n-\theta)\overset{d}\to N_k(0,I_k),
$$
其中 $I_k$ 是单位矩阵，则称 $V_n(\theta)$ 是**渐近协方差矩阵**。

若 Fisher 信息矩阵正定，且渐近方差满足 $V_n(\theta)=I_n(\theta)^{-1}$ （“CRLB”），则称之为 **asymptotially efficient** 或 **aymptotically optimal**.

两组估计，渐近协方差分别为 $V_{1n}(\theta)$ 和 $V_{2n}(\theta)$，若对足够大的 $n$，有 $\forall \theta\in\Theta,\quad V_{2n}(\theta)-V_{1n}(\theta)$ 半正定；且存在某个 $\theta$ 使其正定，则称 $\hat\theta_{1n}$ **asymptotically more efficient than** $\hat\theta_{2n}$.

> 注意：对于渐近无偏的估计，CRLB 不一定对渐近方差成立，例：Hodges' estimator, Lec23 p13.

**Asymptotic relative efficiency**: $T'_n$ 相对于 $T_n$ 的渐近效率为
$$
e_{T'_n,T_n}(P)=\frac{\text{amse}_{T_n}(P)}{\text{amse}_{T'_n}(P)}.
$$
如果 $\limsup_n e_{T'_n,T_n}(P)\le 1$，且存在 $P$ 使 $<$ 成立，则称 $T_n$ **asympotically more efficient**.

**定理（$\delta$-method）** 设 $U_n$ 满足 $a_n(U_n-\theta)\overset{d}\to Y$ 且 $EY^2<\infty$，$a_n>0$，$a_n\to\infty$. 设 $g$ 在 $\theta$ 处可微，$T_n=g(U_n)$ 是$\vartheta=g(\theta)$ 的估计量，则 $\text{amse}_{T_n}=E\{[g'(\theta)Y]^2\}/a_n^2$, $T_n$ 的渐近方差为 $[g'(\theta)^2\mathrm{Var}Y]/a_n^2$.

### 点估计的渐近性质

#### 矩估计

对于矩估计，若 $h^{-1}$ 存在，由大数定律知它是 **strongly consistent**. 

若还有 $h^{-1}$ 可微且 $E|X_1|^{2k}<\infty$ （$k$ 为参数个数），由 CLT 知矩估计 $\sqrt{n}$-consistent. 

若 $k=1$，则 $\text{amse}_{\hat\theta_n}(\theta)=g'(\mu_1)^2\sigma^2/n$.

#### UMVUE

UMVUE 都是一致无偏的。

#### 样本分位数

我们经常用样本分位数做估计量，因此有必要研究它。对 $\gamma\in(0,1)$，第 $\lfloor \gamma n\rfloor$ 个次序统计量被称为 **$\gamma$-sample quantile**. 有如下结论：

**定理** 设 $X_i$ i.i.d.，cdf 为 $F$，若 $F(\theta)=\gamma$，$F'(\theta)$ 存在且不为 0，则第 $\lfloor \gamma n\rfloor$ 个次序统计量 $\tilde{\theta}_n$ 满足
$$
\sqrt{n}\left(\tilde{\theta}_n-\theta\right)\overset{d}\to N\left(0,\frac{\gamma(1-\gamma)}{F'(\theta)^2}\right).
$$

> 证明用到 Berry–Esseen Theorem，略

#### MLE

**定理** 设 $\theta_0$ 为实际参数，并满足以下条件：

- $\Theta$ 是紧集，

- 对任意 $x$，$f(x|\theta)$ 关于 $\theta$ 连续，

- 存在控制函数 $M(x)$ 使得 $E_{\theta_0}|M(X)|<\infty$ 且
  $$
  \left|\log f(x|\theta)-\log f(x|\theta_0)\right|\le M(x),\quad\forall x,\theta,
  $$

- （一致性）$f(x|\theta)=f(x|\theta_0)$ 则 $\theta=\theta_0$.

此时，MLE $\hat\theta_n\overset{a.s.}\to\theta_0$.

> 注：
>
> 1. 连续性可以替换成上半连续，即对任意 $x$，有
>
> $$
> \lim_{\rho\to 0}\sup_{\|\theta'-\theta\|<\rho }f(x|\theta') =f(x|\theta).
> $$
>
> 2. 可以推广到任意度量空间，只需把 $\|\theta-\theta_0\|$ 换成度量 $d(\theta,\theta_0)$. 
> 2. 控制函数 $M(x)$ 的存在性是关键。

#### M-估计

类似于 MLE，有如下结论：

**定理** 有 $S_n,S$ 满足

1. $
\sup_{\theta\in\Theta}|S_n(\theta)-S(\theta)|\overset{p}\to 0$,（一致收敛）
2. $\sup_{\theta:d(\theta,\theta_0)\ge\rho}S(\theta)<S(\theta_0)$，（well-separation）

若估计量 $\hat\theta_n$ 满足 $S_n(\hat\theta_n)\ge S_n(\theta_0)-o_P(1)$，则 $d(\hat\theta_n,\theta_0)\overset{p}\to 0$.

#### RLE

RLE 指的是 roots of likelihood equation，使得 $\dfrac{\partial}{\partial\theta}\log L_n(\theta)=0$ 的点。它和 MLE 有着千丝万缕的联系。事实上，在一定的正则性条件下，它收敛到真实参数，这使得 RLE 具有一致性。

**正则性条件**（basic regularity conditions） 设 $\theta_*$ 是真实值，则

1. $\Theta$ 是 $\mathbb{R}^k$ 中的开集，

2. $f(x|\theta)$ 二阶连续可微，且一二阶导数均可和积分交换，

3. （控制函数）设 $\Psi(x,\theta)=\dfrac{\partial^2}{\partial\theta\partial\theta^T}\log f(x|\theta)$（是矩阵），则存在常数 $c$ 和非负函数 $H$ 使得 $EH(X)<\infty$ 且
   $$
   \sup_{\|\theta-\theta_*\|<c}\|\Psi(x,\theta)\|\le H(x).
   $$

4. （identifiability）$f(x|\theta)=f(x|\theta_*)$ 则 $\theta=\theta_*$.

**定理**（RLE的一致性） 在上述正则性条件下，存在一列 $\hat\theta_n$ 使得 $\dfrac{\partial}{\partial\theta}\log L_n(\hat\theta_n)=0$ 且 $\hat\theta_n\overset{a.s.}\to\theta_*$.

此外，我们可以讨论 RLE 的渐近正态性。

**定理** 设正则性条件成立，且 Fisher 信息矩阵在 $\theta_*$ 处正定，则对任意的一致 RLE 序列 $\tilde{\theta}_n$（比如上一个定理中收敛的 RLE 序列），有
$$
\sqrt{n}(\tilde\theta_n-\theta_*)\overset{d}\to N(0,I(\theta_*)^{-1}).
$$

> 如果 MLE 是一致的，且 MLE 就是 RLE，则它可以用来说明 MLE 的渐近正态性。

