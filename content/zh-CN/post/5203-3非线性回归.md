---
title: "线性回归（三）-非线性回归"
date: 2021-10-12
draft: false
tags: [
"学习",
]
series: ["课程笔记"]
categories: ["课程笔记"]
math: true
---

很多时候，线性模型并不能满足我们的需求，这时候考虑非线性模型是一个不错的选择。但习说不是胡说，改变不是瞎编，我们还是要利用之前学过的线性模型的。

<!--more-->

## 多项式回归

### 基本模型

我们只看单变量的情况，这时候由它的不同次幂构成每一项：
$$
y=\beta_0+\beta_1x+\beta_2x^2+\cdots+\beta_mx^m+\varepsilon,
$$
其中 $\varepsilon\sim N(0,\sigma^2)$.

求解老掉牙了，不说了。

### 问题

我们需要关注它的两个缺点：

- 可能有严重的多重共线性
- 增删某一项之后，其他系数需要重新计算

比如在 $x$ 比较小时，每一列都差不多是 $0$，多重共线性严重。至于第二个缺点，我们可以假设，现在有一个 $m$ 阶的模型，我们发现结果不显著，想引入 $m+1$ 次项。设原来的设计矩阵是 $X_m$，新的设计矩阵为 $X=\begin{pmatrix}X_m &x^{m+1}\end{pmatrix}$. 则
$$
X^TX=
\begin{pmatrix}
X_m^TX_m & X_m^Tx^{m+1}\\\\
(x^{m+1})^TX_m & (x^{m+1})^Tx^{m+1}\\\\
\end{pmatrix}.
$$
这都纠缠到一起了，新的 $\beta_i$ 要重新计算。

### 正交多项式回归

为了解决这一问题，我们引入正交多项式回归。其基本思想是，用一个 $k$ 次多项式 $P_k(x)$ 代替 $x^k$。这时模型变为
$$
y=\beta_0P_0(x)+\beta_1P_1(x)+\cdots+\beta_mP_m(x)+\varepsilon.
$$
多项式正交，采用最直观的定义，即 $\sum_{i=1}^n P(x_i)Q(x_i)=0$ 则称 $P,Q$ 正交。

如果模型中 $P_i,P_j$ 两两正交，计算
$$
X^TX=\begin{pmatrix}
X_m^TX_m & 0\\\\
0 & P_{m+1}(x)^TP_{m+1}(x)\\\\
\end{pmatrix}.
$$
这样当我们在模型中增删项的时候，就不用重新计算系数了。

### 计算正交多项式

一般来说，要算正交多项式就得老老实实列方程算。由于多项式乘个常数没有任何影响，所以 $P_k(x)$ 有 $k$ 个参数。利用 $P_k$ 和 $P_0,\cdots,P_{k-1}$ 正交，就能解出来了。

对于 $x$ 等间隔的情况，有如下的快速计算公式：

![image-20210906152000802](5203\1.png)

其中 $d$ 是间距，$\lambda$ 可自由选择，不影响结果。通常选取 $\lambda$ 使得多项式中各个系数都是整数，好算。

### 参考文献

1. http://home.iitk.ac.in/~shalab/regression/Chapter12-Regression-PolynomialRegression.pdf

## 异方差 - BOX-COX 变换

我们之前的所有模型都假定误差同方差，但现实却经常遇到异方差的情况。这是一个很大的话题，我们这里只简单介绍一种处理方案——对 $y$ 进行 BOX-COX 变换。

BOX-COX 变换有一个参数 $\lambda$，公式为

$$
z=f(y)=\left\{\begin{align}
&\frac{y^\lambda -1}{\lambda},\ \lambda\ne 0,\\\\
&\log y,\ \lambda=0.
\end{align}\right.
$$

这样定义的好处是导数非常简洁：

$$
f'(y)=y^{\lambda-1}.
$$

### 理论分析

我们可以把线性模型表达为 $y=\mu+\varepsilon$，其中 $\mu$ 可以是 $\beta x$ 或者类似的东西，总之就是能被回归解释的部分，$\varepsilon$ 是误差。我们假设标准差是 $\mu$ 的指数函数，即 ${\rm Var}(y)=k\mu^{2\alpha}$. 做变换 $z=f(y)$，在 $\mu$ 处 Taylor 展开：
$$
z=f(y)\approx f(\mu)+ f'(\mu)(y-\mu).
$$
于是
$$
{\rm Var}(z)\approx {\rm Var}(f'(\mu)(y-\mu))=f'(\mu)^2 k\mu^{2\alpha}=k\mu^{2\lambda-2+2\alpha}.
$$
如果 $\lambda=1-\alpha$, 就有
$$
{\rm Var}(z)=k.
$$
是常数了。

### 选取 $\lambda$ - Scaled $\lambda$ Plot

一般我们都是从表里选 $\lambda$:

![](5203/3.png)

把表里的挨个试一遍，每个模型都计算每个系数的 $t$ 值，然后以 $\lambda$ 为横坐标，$t$ 为纵坐标画线。选个合适的。如下图：

![](5203/4.png)

选的原则是，模型简洁，$t$ 越大越好。这里我们选 $\lambda=0$。$\lambda=-1/2$ 虽然大，但是多了个 BC 交叉项，不简洁。

### 选取 $\lambda$ - Empirical Estimation

一个我觉得挺无赖的方法。注意到 $\sigma_i=k\mu_i^{\alpha}$, 有 $\log \sigma_i=\log k +\alpha\log \mu_i$. 线性回归可以得到 $\mu_i$ 和 $\sigma_i$ 的估计，然后再做一次线性回归估计 $\alpha$.

> 可是线性回归的假设是同方差，现在有异方差的情况下估计，不是套娃了吗？

